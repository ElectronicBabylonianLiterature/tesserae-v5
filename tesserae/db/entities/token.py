"""Database standardization for text tokens.

Classes
-------
Token
    Text token data model with matching-related features.
"""
import typing

from bson.objectid import ObjectId

from tesserae.db.entities import Entity


class Token(Entity):
    """An atomic piece of text, along with related features.

    Tokens contain the atomic pieces of text that inform Matches and make
    up Units. In addition to the raw text, the normalized form of the text
    and features like lemmata and semantic meaning are also part of a
    token.

    Parameters
    ----------
    id : bson.objectid.ObjectId, optional
        Database id of the text. Should not be set locally.
    text : str or bson.objectid.ObjectId, optional
        The text containing this token.
    index : int, optional
        The order of this token in the text.
    display : str, optional
        The un-altered form of this token, as it appears in the original
        text.
    feature_set : bson.objectid.ObjectId, optional
        Database id of the features associated with this token. This should be
        generated by the MongoDB instance on insert.


    Attributes
    ----------
    id : bson.objectid.ObjectId
        Database id of the text. Should not be set locally.
    text : str or bson.objectid.ObjectId
        The text containing this token.
    index : int
        The order of this token in the text.
    display : str
        The un-altered form of this token, as it appears in the original
        text.
    feature_set : bson.objectid.ObjectId
        Database id of the features associated with this token. This should be
        generated by the MongoDB instance on insert.

    """

    collection = 'tokens'

    def __init__(self, id=None, text=None, index=None, display=None,
                 feature_set=None):
        super(Token, self).__init__(id=id)
        self.text: typing.Optional[typing.Union[str, ObjectId]] = text
        self.index: typing.Optional[int] = index
        self.display: typing.Optional[str] = display
        self.feature_set: typing.Optional[ObjectId] = feature_set

    def match(self, other, feature):
        """Determine whether two tokens match along a given feature.

        Parameters
        ----------
        other : tesserae.db.entities.Token
            The token to compare against.
        feature : {'form','lemmata','semantic','lemmata + semantic','sound'}
            The feature to compare on.

        Returns
        -------
        match : bool
        """
        if feature == 'word':
            return self.form == other.form
        elif feature == 'lemmata':
            return len(set(self.lemmata) & set(other.lemmata)) > 0
        elif feature == 'semantic':
            return len(set(self.semantic) & set(other.semantic)) > 0
        elif feature == 'sound':
            return len(set(self.sound) & set(other.sound)) > 0
        else:
            return len(set(self.lemmata) & set(other.lemmata)) > 0 and \
                   len(set(self.semantic) & set(other.semantic)) > 0
